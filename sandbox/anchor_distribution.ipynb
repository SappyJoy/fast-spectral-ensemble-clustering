{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# n_samples = 10_000\n",
    "# n_features = 5\n",
    "# data = np.random.rand(n_samples, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dask.array as da\n",
    "\n",
    "# # Suppose 'data' is a numpy array of shape (n_samples, n_features).\n",
    "# # Convert it into a Dask array with a chosen chunk size:\n",
    "# ddata = da.from_array(data, chunks=(1000, data.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install dask-ml  (or pip install dask-ml)\n",
    "# from dask_ml.cluster import KMeans\n",
    "\n",
    "# Example usage:\n",
    "# kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "# or\n",
    "# kmeans = MiniBatchKMeans(n_clusters=2, random_state=42, batch_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import dask.array as da\n",
    "# from dask_ml.cluster import KMeans  # dask-ml KMeans\n",
    "# # from sklearn.metrics import pairwise_distances_argmin  # used later\n",
    "\n",
    "# def recursive_bkmeans_dask(data, num_anchors, current_depth=0, max_depth=None):\n",
    "#     \"\"\"\n",
    "#     Recursively partition data into clusters (balanced K-means style).\n",
    "#     Returns a Python list of Dask array anchors (each anchor is data.mean(axis=0)).\n",
    "#     \"\"\"\n",
    "#     if max_depth is None:\n",
    "#         max_depth = int(np.ceil(np.log2(num_anchors)))\n",
    "    \n",
    "#     # Base cases\n",
    "#     if num_anchors == 1 or data.shape[0] <= 1 or current_depth >= max_depth:\n",
    "#         if data.shape[0] == 0:\n",
    "#             return []\n",
    "#         else:\n",
    "#             # return a Python list with one Dask array (the centroid)\n",
    "#             return [data.mean(axis=0)]\n",
    "\n",
    "#     # Fit + predict with Dask-ML KMeans\n",
    "#     clusterer = KMeans(n_clusters=2, random_state=42)\n",
    "#     clusterer.fit(data)         # data is a Dask array\n",
    "#     labels = clusterer.predict(data)\n",
    "\n",
    "#     left = data[labels == 0]\n",
    "#     right = data[labels == 1]\n",
    "\n",
    "#     num_left = num_anchors // 2\n",
    "#     num_right = num_anchors - num_left\n",
    "\n",
    "#     # Recursively get anchors on left and right\n",
    "#     anchors_left = recursive_bkmeans_dask(left, num_left, current_depth + 1, max_depth)\n",
    "#     anchors_right = recursive_bkmeans_dask(right, num_right, current_depth + 1, max_depth)\n",
    "\n",
    "#     # Return a Python list (concatenate the lists)\n",
    "#     return anchors_left + anchors_right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import pairwise_distances_argmin\n",
    "\n",
    "# def BKHK_dask(data, num_anchors):\n",
    "#     \"\"\"\n",
    "#     data: a Dask array\n",
    "#     Returns:\n",
    "#         anchors: (num_anchors, n_features) NumPy array\n",
    "#         assignments: (n_samples,) NumPy array of nearest-anchor indices\n",
    "#     \"\"\"\n",
    "#     # Build the recursion in Python (no delayed)\n",
    "#     anchors_list = recursive_bkmeans_dask(data, num_anchors)\n",
    "#     # anchors_list is now a plain Python list of Dask arrays\n",
    "\n",
    "#     # Convert each Dask array (anchor) into a NumPy array\n",
    "#     anchors_np = [anchor_da.compute() for anchor_da in anchors_list]\n",
    "#     # Possibly truncate if there are more anchors than needed\n",
    "#     anchors_np = anchors_np[:num_anchors]\n",
    "#     # Stack them together\n",
    "#     anchors = np.stack(anchors_np, axis=0)  # shape = (num_anchors, n_features)\n",
    "\n",
    "#     # Convert data to NumPy for final assignment\n",
    "#     data_np = data.compute()  # shape = (n_samples, n_features)\n",
    "\n",
    "#     # Assign each sample to the nearest anchor\n",
    "#     assignments = pairwise_distances_argmin(data_np, anchors)\n",
    "\n",
    "#     return anchors, assignments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     import numpy as np\n",
    "#     import dask.array as da\n",
    "\n",
    "#     n_samples = 10_000\n",
    "#     n_features = 5\n",
    "#     np_data = np.random.rand(n_samples, n_features)  # random data\n",
    "\n",
    "#     # Convert to Dask array\n",
    "#     ddata = da.from_array(np_data, chunks=(1000, n_features))\n",
    "\n",
    "#     k = 16\n",
    "#     anchors, assignments = BKHK_dask(ddata, k)\n",
    "    \n",
    "#     print(\"Anchors shape:\", anchors.shape)          # (16, 5)\n",
    "#     print(\"Assignments shape:\", assignments.shape)  # (10000,)\n",
    "#     print(\"First few assignments:\", assignments[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchors shape: (16, 5)\n",
      "Assignments shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "from dask_ml.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "\n",
    "def recursive_bkmeans_dask(data, num_anchors, current_depth=0, max_depth=None):\n",
    "    if max_depth is None:\n",
    "        max_depth = int(np.ceil(np.log2(num_anchors)))\n",
    "\n",
    "    if num_anchors == 1 or data.shape[0] <= 1 or current_depth >= max_depth:\n",
    "        if data.shape[0] == 0:\n",
    "            return []\n",
    "        return [data.mean(axis=0)]\n",
    "\n",
    "    clusterer = KMeans(n_clusters=2, random_state=42)\n",
    "    clusterer.fit(data)  # OK as data has known chunk sizes\n",
    "    labels = clusterer.predict(data)\n",
    "\n",
    "    # Must compute labels to know how big left/right will be\n",
    "    labels_np = labels.compute()\n",
    "    data_np = data.compute()\n",
    "\n",
    "    # Split in memory\n",
    "    left_np = data_np[labels_np == 0]\n",
    "    right_np = data_np[labels_np == 1]\n",
    "\n",
    "    # Convert back to dask arrays if you want\n",
    "    left_da = da.from_array(left_np, chunks=(left_np.shape[0], data_np.shape[1]))\n",
    "    right_da = da.from_array(right_np, chunks=(right_np.shape[0], data_np.shape[1]))\n",
    "\n",
    "    num_left = num_anchors // 2\n",
    "    num_right = num_anchors - num_left\n",
    "\n",
    "    anchors_left = recursive_bkmeans_dask(left_da, num_left, current_depth + 1, max_depth)\n",
    "    anchors_right = recursive_bkmeans_dask(right_da, num_right, current_depth + 1, max_depth)\n",
    "\n",
    "    return anchors_left + anchors_right\n",
    "\n",
    "def BKHK_dask(data, num_anchors):\n",
    "    anchors_list = recursive_bkmeans_dask(data, num_anchors)\n",
    "    # anchors_list is a Python list of Dask arrays\n",
    "    anchors_np = [a.compute() for a in anchors_list]\n",
    "    anchors_np = anchors_np[:num_anchors]\n",
    "    anchors = np.stack(anchors_np, axis=0)\n",
    "\n",
    "    # Final assignment\n",
    "    data_np = data.compute()\n",
    "    assignments = pairwise_distances_argmin(data_np, anchors)\n",
    "    return anchors, assignments\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_samples = 10_000\n",
    "    n_features = 5\n",
    "    np_data = np.random.rand(n_samples, n_features)\n",
    "\n",
    "    # Must have known chunk sizes\n",
    "    ddata = da.from_array(np_data, chunks=(1000, n_features))\n",
    "\n",
    "    k = 16\n",
    "    anchors, assignments = BKHK_dask(ddata, k)\n",
    "    print(\"Anchors shape:\", anchors.shape)\n",
    "    print(\"Assignments shape:\", assignments.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
